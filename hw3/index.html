<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Catherine Jin </div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-moop/hw3/index.html">cs184.eecs.berkeley.edu/sp25</a>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-boopie">cs184.eecs.berkeley.edu/sp25</a>
		
		<!-- <figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure> -->

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this project, we built a pathtracer to render images with realistic lighting and shadows. We implemented ray generation and intersection tests with triangles and spheres, accelerating the process using a Bounding Volume Hierarchy (BVH) for efficient ray traversal.

		To simulate lighting, we first computed direct illumination, including zero-bounce and one-bounce, capturing shadows. We then incorporated indirect illumination using Monte Carlo integration to model recursive light bounces, making scenes more realistic. To optimize performance, we applied Russian Roulette for unbiased early termination and adaptive sampling to reduce noise by focusing samples where convergence is slower.

		By integrating these techniques, our pathtracer renders high-quality images with configurable parameters for light bounces and sampling rates.


		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		Camera::generate_ray(...) converts image coordinates (x, y) to a world-space ray. It maps (x,y) to camera space using the field of view, then transforms the direction using c2w. The ray originates from pos and is normalized, with near and far clipping planes (nClip, fClip).

		<p>The primitive intersection stage of the rendering pipeline determines how rays interact with scene geometry, such as spheres. When a ray is cast, its intersection with a sphere is computed by solving a quadratic equation derived from substituting the ray equation into the sphere equation. If the discriminant is non-negative, the ray intersects the sphere, and the smaller positive root gives the nearest intersection. The test function computes intersection times and checks if a hit occurs. The has_intersection function determines if a shadow ray hits the sphere, updating r.max_t accordingly. The intersect function records details such as hit point, surface normal, and material properties in an Intersection struct. This process is essential for shading and lighting calculations, ensuring accurate rendering of objects in the scene.</p>

		<p>The triangle intersection algorithm I implemented is based on the Moller Trumbore method, which efficiently determines if a ray intersects a given triangle in 3D space. First, the algorithm computes two edge vectors, e1 and e2, from the triangle's vertices. Then, it calculates a determinant using the cross product of the ray direction and e2, followed by the dot product with e1. If the determinant is close to zero, the ray is nearly parallel to the triangle, so no intersection occurs. Otherwise, the algorithm computes the inverse determinant and uses it to find the barycentric coordinates u and v, ensuring they lie within the valid range (0 ≤ u, v ≤ 1 and u+v ≤ 1). If valid, it calculates the intersection time t along the ray and ensures it is within the ray's valid range. The has_intersection function only checks for intersection, while intersect records intersection details such as the hit point, interpolated normal (using barycentric weights), and material properties. This method is both efficient and widely used in ray tracing due to its minimal floating-point operations and lack of explicit division.</p>

		<p>Here, we show images with normal shading for a few small .dae files.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="banana.png" width="400px"/>
				  <figcaption>banana.png after task 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cbempty.png" width="400px"/>
				  <figcaption>CBempty.png after task 2</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>These are some renderings of the .dae files after finishing the entirety of part 1.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="CBemptytask3.png" width="400px"/>
				  <figcaption>CBempty after task 3</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="CBspheres.png" width="400px"/>
				  <figcaption>CBspheres.png after task 4</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		The BVH construction algorithm follows a recursive top-down approach, where each node in the tree represents an axis-aligned bounding box that encloses a subset of primitives. The construction begins by computing a bounding box around all primitives. If the number of primitives in the current node is less than or equal to the maximum leaf size, the node becomes a leaf containing those primitives. Otherwise, the algorithm selects a splitting axis based on the extent of the bounding box, choosing the longest axis to maximize separation. The splitting point is determined by computing the average centroid position of all primitives along the chosen axis. The primitives are then partitioned into two groups based on whether their centroids fall below or above the split point. If partitioning results in an empty or unbalanced split, the algorithm defaults to a median split. The process repeats recursively until all primitives are organized into leaf nodes. This heuristic helps improve spatial partitioning and traversal efficiency by ensuring a relatively balanced tree with well-separated bounding boxes.

		<p>These are some renderings of the large .dae files.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="CBlucypt2.png" width="400px"/>
				  <figcaption>CBlucy.png after part 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="maxplanckpt2.png" width="400px"/>
				  <figcaption>maxplanck.png after part 2</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>Before BVH, CBlucy.dae took around 100 seconds to render, and maxplanck.dae took around 90 seconds to render. After BVH, both images only took around 2 seconds to render, showing a much faster and efficient result. This is because by implementing BVH, it allows us to skip checking the intersections of the primitives. The more intersection checks we can skip, the faster the rendering process becomes.</p>

		<h2>Part 3: Direct Illumination</h2>
		<p>In PathTracer::estimate_direct_lighting_hemisphere, lighting is estimated by uniformly sampling directions over a hemisphere centered around the surface normal. A coordinate system is created at the intersection point with the normal aligned to the Z-axis. The outgoing direction w_out is computed from the ray direction. The function then iterates num_samples times, where each iteration samples a random direction wi_local using a hemisphere sampler. This direction is converted to world space and used to construct a shadow ray. If the shadow ray intersects an emissive surface, the emitted radiance L_j is obtained. The final contribution from this sample is computed using the BRDF, cosine weighting, and the PDF of uniform hemisphere sampling (1 / 2π). The contributions are averaged over all samples to estimate the direct lighting.</p>

		<p>In PathTracer::estimate_direct_lighting_importance, efficiency is improved by only sampling directions from actual light sources instead of uniformly over a hemisphere. For each light source in the scene, the function determines the number of samples (ns_area_light for area lights, 1 for delta lights). The light's sample_L function is used to generate a sample direction wi, compute the emitted radiance L_i, and determine the PDF. A shadow ray is then traced to check for occlusion. If the sample is not blocked, the contribution is computed using the BRDF, cosine term, and PDF. The function accumulates these values over multiple samples and averages them if the light is not a delta light. This method ensures that more samples are taken from important directions, leading to a more accurate and noise-free estimate of direct lighting.</p>

		<p>Here, we compare hemisphere sampling vs importance sampling.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="bunnyhemisphere.png" width="400px"/>
				  <figcaption>bunny uniform hemisphere</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="bunnyimportance.png" width="400px"/>
				  <figcaption>bunny importance</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="bunnyl1.png" width="400px"/>
				  <figcaption>bunny 1 light ray</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="bunnyl4.png" width="400px"/>
				  <figcaption>bunny 4 light rays</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="bunnyl16.png" width="400px"/>
				  <figcaption>bunny 16 light rays</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="bunnyl64.png" width="400px"/>
				  <figcaption>bunny 64 light rays</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Uniform hemisphere sampling provides a more general but less efficient approach to estimating direct lighting since it samples all directions equally, many of which may contribute little to the final radiance due to occlusion or the absence of light sources, often leading to high variance and noise, requiring a large number of samples to achieve a smooth result. Whereas, light sampling focuses sampling on actual light sources, significantly improving efficiency by reducing wasted samples in unimportant directions. This method leads to faster convergence and lower noise, especially in scenes with small or distant lights, though it may miss indirect illumination effects if not combined with additional global illumination techniques. Consequently, importance sampling typically produces cleaner, more accurate renders with fewer samples compared to uniform hemisphere sampling.</p>

		<h2>Part 4: Global Illumination</h2>
		Walk through your implementation of the indirect lighting function:
		I implemented the indirect lighting function is implemented in at_least_one_bounce_radiance(), which recursively calculates global illumination by simulating multiple bounces of light. It first computes direct illumination using one_bounce_radiance(), then checks if the ray has remaining depth to continue tracing indirect light. If the recursion depth allows, it samples a new direction using the BSDF function, generates a new ray, and recursively calls itself for the next bounce. Russian roulette is used to probabilistically terminate low-contribution paths, ensuring efficiency. If a valid intersection is found, it computes the contribution using the BRDF, cosine term, and probability density, accumulating the result. The function balances efficiency and accuracy by adaptively terminating low-contribution paths while capturing realistic indirect lighting effects.

		<p>Here are some images rendered with global (direct and indirect) illumination. Using 1024 samples per pixel.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="dragon_64_32.png" width="400px"/>
				  <figcaption>dragon</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="spheres.png" width="400px"/>
				  <figcaption>spheres</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pt4dir.png" width="400px"/>
				  <figcaption>spheres with direct illumination</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt4indir.png" width="400px"/>
				  <figcaption>spheres with indirect illumination</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>For CBbunny.dae, render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag), and isAccumBounces=false. Explain in your write-up what you see for the 2nd and 3rd bounce of light, and how it contributes to the quality of the rendered image compared to rasterization. Use 1024 samples per pixel. Then compare it to accumulated bounces</p>
		<p>isAccumBounces = false NEED TO ADD</p>

		<p>isAccumBounces = true</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pt4m0.png" width="150px"/>
				  <figcaption>0th bounce</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt4m1.png" width="150px"/>
				  <figcaption>1st bounce</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="pt4m2.png" width="150px"/>
					<figcaption>2nd bounce</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="pt4m3.png" width="150px"/>
					<figcaption>3rd bounce</figcaption>
				  </td>

				  <td style="text-align: center;">
					<img src="pt4m4.png" width="150px"/>
					<figcaption>4th bounce</figcaption>
				  </td>
				  <td style="text-align: center;">
					<img src="pt4m5.png" width="150px"/>
					<figcaption>5th bounce</figcaption>
				  </td>
			  </tr>
			</table>
		</div>

		<p>CBbunny.dae, output the Russian Roulette rendering with max_ray_depth set to 0, 1, 2, 3, 4, and 100</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pt4m0.png" width="150px"/>
				  <figcaption>depth: 0</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt4m1.png" width="150px"/>
				  <figcaption>depth: 1</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="pt4m2.png" width="150px"/>
					<figcaption>depth: 2</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="pt4m3.png" width="150px"/>
					<figcaption>depth: 3</figcaption>
				  </td>

				  <td style="text-align: center;">
					<img src="pt4m4.png" width="150px"/>
					<figcaption>depth: 4</figcaption>
				  </td>
				  <td style="text-align: center;">
					<img src="pt4rr100.png" width="150px"/>
					<figcaption>depth: 100</figcaption>
				  </td>
			  </tr>
			</table>
		</div>

		<p>Wall-e renders. Compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="walle1.png" width="200px"/>
				  <figcaption>1 sample per pixel</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="walle2.png" width="200px"/>
				  <figcaption>2 samples per pixel</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="walle4.png" width="200px"/>
					<figcaption>4 samples per pixel</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="walle8.png" width="200px"/>
					<figcaption>8 samples per pixel</figcaption>
			  </tr>
			  <tr>
				</td>
				<td style="text-align: center;">
					<img src="walle16.png" width="200px"/>
					<figcaption>16 samples per pixel</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="walle64.png" width="200px"/>
					<figcaption>64 samples per pixel</figcaption>
				</td>
				<td style="text-align: center;">
					<img src="walle1024.png" width="200px"/>
					<figcaption>1024 samples per pixel</figcaption>
				</td>
				</tr>
			</table>
		</div>


		<h2>Part 5: Adaptive Sampling</h2>
		Adaptive sampling is a technique used to optimize rendering by dynamically adjusting the number of samples per pixel based on variance, reducing computation while maintaining image quality. Instead of always using a fixed number of samples, my implementation starts with ns_aa samples and iteratively traces rays through the scene. It accumulates radiance values while tracking luminance statistics (sum_illum and sum_illum_squared). Every samplesPerBatch iterations, the algorithm estimates the mean and variance, then calculates a confidence interval using standard deviation. If this confidence interval falls below maxTolerance * mean, the pixel is considered converged, and sampling stops early. This method ensures smooth regions receive fewer samples, while complex or noisy areas get more, leading to efficient and high-quality rendering. The final color is averaged and stored in sampleBuffer, with the sample count recorded in sampleCountBuffer to track the adaptive sampling process.

		<p>dragon.dae</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="task5dragon.png" width="400px"/>
				  <figcaption>dragon.dae rendered result</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="task5dragon_rate.png" width="400px"/>
				  <figcaption>dragon.dae sample rate image</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>wall-e.dae</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="task5walle.png" width="400px"/>
				  <figcaption>wall-e.dae rendered result</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="task5walle_rate.png" width="400px"/>
				  <figcaption>wall-e.dae sample rate image</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		
		</div>
	</body>
</html>