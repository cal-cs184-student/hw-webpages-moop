<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Catherine Jin </div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-moop/hw3/index.html">cs184.eecs.berkeley.edu/sp25</a>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-boopie">cs184.eecs.berkeley.edu/sp25</a>
		
		<!-- <figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure> -->

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this project, we built a pathtracer to render images with realistic lighting and shadows. We implemented ray generation and intersection tests with triangles and spheres, accelerating the process using a Bounding Volume Hierarchy (BVH) for efficient ray traversal.

		To simulate lighting, we first computed direct illumination, including zero-bounce and one-bounce, capturing shadows. We then incorporated indirect illumination using Monte Carlo integration to model recursive light bounces, making scenes more realistic. To optimize performance, we applied Russian Roulette for unbiased early termination and adaptive sampling to reduce noise by focusing samples where convergence is slower.

		By integrating these techniques, our pathtracer renders high-quality images with configurable parameters for light bounces and sampling rates.


		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		Camera::generate_ray(...) converts image coordinates (x, y) to a world-space ray. It maps (x,y) to camera space using the field of view, then transforms the direction using c2w. The ray originates from pos and is normalized, with near and far clipping planes (nClip, fClip).

		<p>The primitive intersection stage of the rendering pipeline determines how rays interact with scene geometry, such as spheres. When a ray is cast, its intersection with a sphere is computed by solving a quadratic equation derived from substituting the ray equation into the sphere equation. If the discriminant is non-negative, the ray intersects the sphere, and the smaller positive root gives the nearest intersection. The test function computes intersection times and checks if a hit occurs. The has_intersection function determines if a shadow ray hits the sphere, updating r.max_t accordingly. The intersect function records details such as hit point, surface normal, and material properties in an Intersection struct. This process is essential for shading and lighting calculations, ensuring accurate rendering of objects in the scene.</p>

		<p>The triangle intersection algorithm I implemented is based on the Moller Trumbore method, which efficiently determines if a ray intersects a given triangle in 3D space. First, the algorithm computes two edge vectors, e1 and e2, from the triangle's vertices. Then, it calculates a determinant using the cross product of the ray direction and e2, followed by the dot product with e1. If the determinant is close to zero, the ray is nearly parallel to the triangle, so no intersection occurs. Otherwise, the algorithm computes the inverse determinant and uses it to find the barycentric coordinates u and v, ensuring they lie within the valid range (0 ≤ u, v ≤ 1 and u+v ≤ 1). If valid, it calculates the intersection time t along the ray and ensures it is within the ray's valid range. The has_intersection function only checks for intersection, while intersect records intersection details such as the hit point, interpolated normal (using barycentric weights), and material properties. This method is both efficient and widely used in ray tracing due to its minimal floating-point operations and lack of explicit division.</p>

		<p>Here, we show images with normal shading for a few small .dae files.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="banana.png" width="400px"/>
				  <figcaption>banana.png after task 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cbempty.png" width="400px"/>
				  <figcaption>CBempty.png after task 2</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>These are some renderings of the .dae files after finishing the entirety of part 1.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="CBemptytask3.png" width="400px"/>
				  <figcaption>CBempty after task 3</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="CBspheres.png" width="400px"/>
				  <figcaption>CBspheres.png after task 4</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		The BVH construction algorithm follows a recursive top-down approach, where each node in the tree represents an axis-aligned bounding box that encloses a subset of primitives. The construction begins by computing a bounding box around all primitives. If the number of primitives in the current node is less than or equal to the maximum leaf size, the node becomes a leaf containing those primitives. Otherwise, the algorithm selects a splitting axis based on the extent of the bounding box, choosing the longest axis to maximize separation. The splitting point is determined by computing the average centroid position of all primitives along the chosen axis. The primitives are then partitioned into two groups based on whether their centroids fall below or above the split point. If partitioning results in an empty or unbalanced split, the algorithm defaults to a median split. The process repeats recursively until all primitives are organized into leaf nodes. This heuristic helps improve spatial partitioning and traversal efficiency by ensuring a relatively balanced tree with well-separated bounding boxes.

		<p>These are some renderings of the large .dae files.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="CBlucypt2.png" width="400px"/>
				  <figcaption>CBlucy after part 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="maxplanckpt2.png" width="400px"/>
				  <figcaption>maxplanck.png after part 2</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>Before BVH, CBlucy.dae took around 100 seconds to render, and maxplanck.dae took around 90 seconds to render. After BVH, both images only took around 2 seconds to render, showing a much faster and efficient result. This is because by implementing BVH, it allows us to skip checking the intersections of the primitives. The more intersection checks we can skip, the faster the rendering process becomes.</p>

		<h2>Part 3: Direct Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>